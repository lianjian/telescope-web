# telescope-web

Telescope is a machine learning application for image matting developed in python.
It takes two images as input: an RGB image or video frame containing a subject you wish to cut out,
and a single channel image called a trimap consisting of three regions. These regions consist of 
the definite foreground of the subject to be cut out (white), the definite background to be excluded (black), 
and the uncertain region (gray), such as the edges of the subject.

It outputs an alphamatte generated by the trained model, consisting of just the foreground and background regions which 
allows the user to cut the subject out of the frame.

This tool has applications in video compositing/effects and can greatly reduce the amount of time and skill needed for techniques like rotoscoping.

This repository is a simple flask application that allows users to play around with the model by drawing trimaps over an image in an html canvas to generate an alphamatte.
Visit [telescope-nn](https://github.com/brendanvonhofe/telescope-nn) if you wish to experiment with and train the nueral net on your own, developed by [brendanvonhofe](https://github.com/brendanvonhofe).


### Building (Linux)
Requires:  
python3  
pip  
git  
wget  
tar  

```
git clone https://github.com/philipmvitale/telescope-web.git
cd telescope-web
sh build_dev.sh
```

### Running

```
sh run_dev.sh
```

## Authors

* **Connor O'Hara** - *System Architect* - [S1nus](https://github.com/S1nus)

* **Kevin Poli** - *Artist Tools/Application Developer* - [kjpoli](https://github.com/kjpoli)

* **Philip Vitale** - *Website/Application Developer* - [philipmvitale](https://github.com/philipmvitale)

* **Brendan von Hofe** - *Core Machine Learning Developer* - [brendanvonhofe](https://github.com/brendanvonhofe)


## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details

## Acknowledgments

* [Deep Image Matting: Ning Xu, Brian Price, Scott Cohen, Thomas Huang; The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017](https://arxiv.org/abs/1703.03872v3)
